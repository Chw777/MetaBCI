# -*- coding: utf-8 -*-
# License: MIT License
"""
SSAVEP Feedback on NeuroScan.

"""

import numpy as np
import time
import numpy as np
import serial
import threading
import mne
from mne.filter import resample
from pylsl import StreamInfo, StreamOutlet
from metabci.brainflow.amplifiers import NeuroScan, Marker,Neuracle
from metabci.brainflow.workers import ProcessWorker
from metabci.brainda.algorithms.decomposition.base import generate_filterbank
from metabci.brainda.algorithms.utils.model_selection \
    import EnhancedLeaveOneGroupOut
from metabci.brainda.algorithms.decomposition.csp import FBCSP
from metabci.brainda.utils import upper_ch_names
from mne.io import read_raw_cnt
from sklearn.svm import SVC
from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.pipeline import make_pipeline
from scipy import signal
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, TensorDataset
from sklearn.metrics import accuracy_score
import sys
import os
import sys
import os

# from secnet import BaseModel
from metabci.brainda.algorithms.deep_learning.secnet import BaseModel
from metabci.brainda.algorithms.deep_learning.tmransnet import tmransnet
from metabci.brainda.algorithms.deep_learning.cttnet import cttnet

def label_encoder(y, labels):
    new_y = y.copy()
    for i, label in enumerate(labels):
        ix = (y == label)
        new_y[ix] = i
    return new_y


class MaxClassifier(BaseEstimator, ClassifierMixin):
    def __init__(self):
        pass

    def fit(self, X, y):
        pass

    def predict(self, X):
        X = X.reshape((-1, X.shape[-1]))
        y = np.argmax(X, axis=-1)
        return y



import mne, os, re
import numpy as np


def read_annotations_bdf(annotations):
    pat = '([+-]\\d+\\.?\\d*)(\x15(\\d+\\.?\\d*))?(\x14.*?)\x14\x00'
    if isinstance(annotations, str):
        with open(annotations, encoding='latin-1') as annot_file:
            triggers = re.findall(pat, annot_file.read())
    else:
        tals = bytearray()
        for chan in annotations:
            this_chan = chan.ravel()
            if this_chan.dtype == np.int32:  # BDF
                this_chan.dtype = np.uint8
                this_chan = this_chan.reshape(-1, 4)
                # Why only keep the first 3 bytes as BDF values
                # are stored with 24 bits (not 32)
                this_chan = this_chan[:, :3].ravel()
                for s in this_chan:
                    tals.extend(s)
            else:
                for s in this_chan:
                    i = int(s)
                    tals.extend(np.uint8([i % 256, i // 256]))

        # use of latin-1 because characters are only encoded for the first 256
        # code points and utf-8 can triggers an "invalid continuation byte"
        # error
        triggers = re.findall(pat, tals.decode('latin-1'))

    events = []
    for ev in triggers:
        onset = float(ev[0])
        duration = float(ev[2]) if ev[2] else 0
        for description in ev[3].split('\x14')[1:]:
            if description:
                events.append([onset, duration, description])
    return zip(*events) if events else (list(), list(), list())


def readbdfdata(filename, pathname):
    '''
    Parameters
    ----------

    filename: list of str

    pathname: list of str

    Return:
    ----------
    eeg dictionary

    '''

    eeg = dict(data=[], events=[], srate=[], ch_names=[], nchan=[])

    if 'edf' in filename[0]:  ## DSI
        raw = mne.io.read_raw_edf(os.path.join(pathname[0], filename[0]), verbose=False)
        raw.drop_channels("FT7")
        raw.drop_channels("Fpz")
        data, _ = raw[:-1]
        events = mne.find_events(raw)
        ch_names = raw.info['ch_names']
        fs = raw.info['sfreq']
        nchan = raw.info['nchan']
    else:
        # Neuracle
        # read data
        raw = mne.io.read_raw_bdf(os.path.join(pathname[0], 'data.bdf'), preload=False, verbose=False)
        ch_names = raw.info['ch_names']
        data, _ = raw[:len(ch_names)]
        fs = raw.info['sfreq']
        nchan = raw.info['nchan']
        # read events
        try:
            annotationData = mne.io.read_raw_bdf(os.path.join(pathname[0], 'evt.bdf'), verbose=False)
            try:
                tal_data = annotationData._read_segment_file([], [], 0, 0, int(annotationData.n_times), None, None)
                # print('mne version <= 0.20')
            except:
                idx = np.empty(0, int)
                tal_data = annotationData._read_segment_file(np.empty((0, annotationData.n_times)), idx, 0, 0,
                                                             int(annotationData.n_times), np.ones((len(idx), 1)), None)
                # print('mne version > 0.20')
            onset, duration, description = read_annotations_bdf(tal_data[0])
            onset = np.array([i * fs for i in onset], dtype=np.int64)
            duration = np.array([int(i) for i in duration], dtype=np.int64)
            desc = np.array([int(i) for i in description], dtype=np.int64)
            events = np.vstack((onset, duration, desc)).T
        except:
            # print('not found any event')
            events = []

    eeg['data'] = data
    eeg['events'] = events
    eeg['srate'] = fs
    eeg['ch_names'] = ch_names
    eeg['nchan'] = nchan
    return eeg




# è®­ç»ƒæ¨¡å‹


def train_model(X, y, srate=1000):
    """ä½¿ç”¨SecNetçš„BaseModelè®­ç»ƒæ¨¡å‹"""
    # ç¡®ä¿è¾“å…¥æ˜¯æ­£ç¡®çš„å½¢çŠ¶
    y = np.reshape(y, (-1))
    # è½¬æ¢ä¸ºPyTorchå¼ é‡
    X_tensor = torch.FloatTensor(X)
    y_tensor = torch.LongTensor(y)

    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    from sklearn.model_selection import train_test_split
    X_train, X_val, y_train, y_val = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)
    print('X_train',X_train.shape)
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_dataset = TensorDataset(X_train, y_train)
    val_dataset = TensorDataset(X_val, y_val)

    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)

    # é…ç½®æ¨¡å‹å‚æ•°
    configs = {
        'class_num': len(np.unique(y)),  # åˆ†ç±»æ•°é‡ï¼Œæ ¹æ®å®é™…æ ‡ç­¾ç¡®å®š
        'channelNum': 58,  # é€šé“æ•°é‡
        'width': 300,  # æ—¶é—´ç‚¹æ•°é‡
        'drop_att': 0.2,  # æ³¨æ„åŠ›æœºåˆ¶çš„dropoutæ¦‚ç‡
        'p': 3  # å…¶ä»–è‡ªå®šä¹‰å‚æ•°
    }

    # åˆå§‹åŒ–æ¨¡å‹
    model = BaseModel(configs)
    # model = tmransnet()
    # model = cttnet()
    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-4)

    # è®­ç»ƒæ¨¡å‹
    num_epochs = 100
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)

    best_val_acc = 0.0
    for epoch in range(num_epochs):
        model.train()
        train_loss = 0.0
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs, _ = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            train_loss += loss.item() * inputs.size(0)

        train_loss /= len(train_loader.dataset)

        # éªŒè¯
        model.eval()
        val_loss = 0.0
        all_preds = []
        all_labels = []

        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs, _ = model(inputs)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * inputs.size(0)

                _, preds = torch.max(outputs, 1)
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())

        val_loss /= len(val_loader.dataset)
        val_acc = accuracy_score(all_labels, all_preds)

        print(
            f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(model.state_dict(), 'best_model.pth')

    # åŠ è½½æœ€ä½³æ¨¡å‹
    model.load_state_dict(torch.load('best_model.pth'))
    model.to(device)

    return model, device

# é¢„æµ‹æ ‡ç­¾

def model_predict(X, srate=1000, model=None, device=None):
    """ä½¿ç”¨è®­ç»ƒå¥½çš„BaseModelè¿›è¡Œé¢„æµ‹"""
    if model is None:
        raise ValueError("æ¨¡å‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")

    # è½¬æ¢ä¸ºPyTorchå¼ é‡
    X_tensor = torch.FloatTensor(X).to(device)

    # é¢„æµ‹
    model.eval()
    with torch.no_grad():
        outputs, _ = model(X_tensor)
        _, preds = torch.max(outputs, 1)

    return preds.cpu().numpy()

# è®¡ç®—ç¦»çº¿æ­£ç¡®ç‡


def offline_validation(X, y, srate=1000):
    """ä½¿ç”¨äº¤å‰éªŒè¯è¯„ä¼°BaseModelæ¨¡å‹æ€§èƒ½"""
    y = np.reshape(y, (-1))
    spliter = EnhancedLeaveOneGroupOut(return_validate=False)
    kfold_accs = []
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    for train_ind, test_ind in spliter.split(X, y=y):
        X_train, y_train = np.copy(X[train_ind]), np.copy(y[train_ind])
        X_test, y_test = np.copy(X[test_ind]), np.copy(y[test_ind])

        # è®­ç»ƒæ¨¡å‹ï¼Œè·å–æ¨¡å‹å’Œè®¾å¤‡
        model, device = train_model(X_train, y_train, srate=srate)
        model.to(device)

        # è°ƒæ•´æµ‹è¯•æ•°æ®å½¢çŠ¶
        X_test_reshaped = np.reshape(X_test, (-1, X_test.shape[-2], X_test.shape[-1]))

        # é¢„æµ‹æ—¶ï¼Œåªä¼ æ¨¡å‹å’Œè®¾å¤‡åˆ° model_predict
        p_labels = model_predict(X_test_reshaped, srate=srate, model=model, device=device)
        kfold_accs.append(np.mean(p_labels == y_test))

    return np.mean(kfold_accs)


class FeedbackWorker(ProcessWorker):
    def __init__(self,
                 stim_interval,
                 stim_labels,
                 srate,
                 lsl_source_id,
                 timeout,
                 worker_name,
                 left_com='COM4',  # å·¦æ‰‹æœºæ¢°æ‰‹ä¸²å£
                 right_com='COM5',  # å³æ‰‹æœºæ¢°æ‰‹ä¸²å£
                 baudrate=57600):  # æ³¢ç‰¹ç‡
        # åˆå§‹åŒ–çˆ¶ç±»
        self.stim_interval = stim_interval
        self.stim_labels = stim_labels
        self.srate = srate
        self.lsl_source_id = lsl_source_id
        super().__init__(timeout=timeout, name=worker_name)

        # æœºæ¢°æ‰‹é…ç½®
        self.left_com = left_com
        self.right_com = right_com
        self.baudrate = baudrate
        self.serial_left = None  # å·¦æ‰‹ä¸²å£å¯¹è±¡
        self.serial_right = None  # å³æ‰‹ä¸²å£å¯¹è±¡
        self.estimator = None
        self.device = None
    def pre(self):
        """é¢„å¤„ç†é˜¶æ®µï¼šåˆå§‹åŒ–æ¨¡å‹å’Œä¸²å£"""
        # 1. åˆå§‹åŒ–ä¸²å£è¿æ¥
        try:
            self.serial_left = serial.Serial(
                port=self.left_com,
                baudrate=self.baudrate,
                timeout=0.1
            )
            print(f"âœ… å·²è¿æ¥å·¦æ‰‹æœºæ¢°æ‰‹: {self.left_com}")
        except Exception as e:
            print(f"âŒ å·¦æ‰‹æœºæ¢°æ‰‹è¿æ¥å¤±è´¥: {e}")
            self.serial_left = None

        try:
            self.serial_right = serial.Serial(
                port=self.right_com,
                baudrate=self.baudrate,
                timeout=0.1
            )
            print(f"âœ… å·²è¿æ¥å³æ‰‹æœºæ¢°æ‰‹: {self.right_com}")
        except Exception as e:
            print(f"âŒ å³æ‰‹æœºæ¢°æ‰‹è¿æ¥å¤±è´¥: {e}")
            self.serial_right = None

        # 2. åŠ è½½æ•°æ®å¹¶è®­ç»ƒæ¨¡å‹
        filename = ['data.bdf', 'evt.bdf']
        print('åŠ è½½æ•°æ®æ–‡ä»¶...')
        file = readbdfdata(filename, [r"D:\Research\MetaBCI\MetaBCI-master2\MetaBCI-master\my_data"])
        print('æ•°æ®åŠ è½½å®Œæˆ')
        sfreq = file['srate']
        print(f'é‡‡æ ·ç‡: {sfreq}')
        nchannel = file['nchan']
        print(f'é€šé“æ•°: {nchannel}')

        # å¤„ç†æ ‡ç­¾
        event = file['events']
        labels = np.delete(event, 1, axis=1)  # åˆ é™¤ç¬¬äºŒåˆ—
        print(f'äº‹ä»¶æ ‡ç­¾: {labels}')

        # å¤„ç†æ•°æ®
        data = file['data']
        print(f'åŸå§‹æ•°æ®å½¢çŠ¶: {data.shape}')
        data = data[1:-5, :]  # å»é™¤æ— å…³é€šé“
        print(f'å¤„ç†åæ•°æ®å½¢çŠ¶: {data.shape}')

        # æˆªå–trial
        trial_length = 4000
        gesture_types = labels[:, 1] - 1  # æ ‡ç­¾ä»0å¼€å§‹

        # æå–æ‰€æœ‰trial
        trials = []
        for idx, (start, hand) in enumerate(labels):
            end = start + trial_length
            if end > data.shape[1]:
                raise ValueError(f"æ ‡ç­¾ {idx} è¶…å‡ºæ•°æ®é•¿åº¦")
            trial_data = data[:, start:end]
            trials.append(trial_data)
        trials_array = np.array(trials)
        print(f'trialæ•°æ®å½¢çŠ¶: {trials_array.shape}')

        # é¢„å¤„ç†æ•°æ®ï¼ˆæ»¤æ³¢ã€é™é‡‡æ ·ï¼‰
        original_sfreq = 1000
        target_sfreq = 250
        filtered_downsampled_data = []
        for trial in trials_array:
            info = mne.create_info(
                ch_names=[f'ch{i}' for i in range(trial.shape[0])],
                sfreq=original_sfreq,
                ch_types=['eeg'] * trial.shape[0]
            )
            raw = mne.io.RawArray(trial, info)
            raw.filter(l_freq=0.5, h_freq=40, fir_design='firwin')
            raw.resample(target_sfreq)
            filtered_downsampled_data.append(raw.get_data())
        filtered_downsampled_data = np.array(filtered_downsampled_data)
        print(f'é¢„å¤„ç†åæ•°æ®å½¢çŠ¶: {filtered_downsampled_data.shape}')

        # # ç¦»çº¿éªŒè¯
        # acc = offline_validation(filtered_downsampled_data, gesture_types, srate=self.srate)
        # print(f"ç¦»çº¿äº¤å‰éªŒè¯å‡†ç¡®ç‡: {acc:.2f}")

        # è®­ç»ƒæ¨¡å‹
        model, device = train_model(filtered_downsampled_data, gesture_types, srate=self.srate)
        self.estimator = model  # åªä¿å­˜æ¨¡å‹å¯¹è±¡
        self.device = device  # å•ç‹¬ä¿å­˜è®¾å¤‡ä¿¡æ¯

        # åˆå§‹åŒ–LSLè¾“å‡º
        info = StreamInfo(
            name='meta_feedback',
            type='Markers',
            channel_count=1,
            nominal_srate=0,
            channel_format='int32',
            source_id=self.lsl_source_id
        )
        self.outlet = StreamOutlet(info)
        print('ç­‰å¾…LSLè¿æ¥...')
        while not self._exit:
            if self.outlet.wait_for_consumers(1e-3):
                break
        print('LSLè¿æ¥æˆåŠŸ')

    def control_robot(self, label):
        """æ§åˆ¶æœºæ¢°æ‰‹è¿åŠ¨"""
        # ç¡®ä¿ä¸²å£å·²è¿æ¥
        if label == 0 and self.serial_left:  # å·¦æ‰‹
            try:
                # æœºæ¢°æ‰‹æ§åˆ¶å‘½ä»¤ï¼ˆæ ¹æ®å®é™…åè®®è°ƒæ•´ï¼‰
                self.serial_left.write(b'A3')  # åˆå§‹åŒ–å‘½ä»¤
                time.sleep(1)
                self.serial_left.write(b'G5')  # è¿åŠ¨å‘½ä»¤
                time.sleep(4.5)
                self.serial_left.write(b'G5')  # å¤ä½å‘½ä»¤
                time.sleep(2)
                print("âœ… å·¦æ‰‹æœºæ¢°æ‰‹è¿åŠ¨å®Œæˆ")
            except Exception as e:
                print(f"âŒ å·¦æ‰‹æœºæ¢°æ‰‹æ§åˆ¶å¤±è´¥: {e}")

        elif label == 1 and self.serial_right:  # å³æ‰‹
            try:
                self.serial_right.write(b'A3')  # åˆå§‹åŒ–å‘½ä»¤
                time.sleep(1)
                self.serial_right.write(b'G5')  # è¿åŠ¨å‘½ä»¤
                time.sleep(4.5)
                self.serial_right.write(b'G5')  # å¤ä½å‘½ä»¤
                time.sleep(2)
                print("âœ… å³æ‰‹æœºæ¢°æ‰‹è¿åŠ¨å®Œæˆ")
            except Exception as e:
                print(f"âŒ å³æ‰‹æœºæ¢°æ‰‹æ§åˆ¶å¤±è´¥: {e}")

    def consume(self, data):
        """å®æ—¶å¤„ç†ï¼šé¢„æµ‹å¹¶æ§åˆ¶æœºæ¢°æ‰‹"""
        data = np.array(data, dtype=np.float64).T  # è½¬ç½®ä¸º [é€šé“, æ—¶é—´]
        data = data[1:-6, :]  # 65é€šé“ â†’ 58é€šé“
        try:
            # æ¨¡å‹é¢„æµ‹
            from scipy import signal
            original_sfreq = 1000  # åŸå§‹é‡‡æ ·ç‡ï¼ˆä¸ç¦»çº¿ä¸€è‡´ï¼‰
            target_sfreq = 250  # ç›®æ ‡é‡‡æ ·ç‡ï¼ˆä¸ç¦»çº¿ä¸€è‡´ï¼‰

            # åˆ›å»ºMNEä¿¡æ¯å¯¹è±¡ï¼ˆé€šé“åã€é‡‡æ ·ç‡ã€é€šé“ç±»å‹ï¼‰
            info = mne.create_info(
                ch_names=[f'ch{i}' for i in range(data.shape[0])],  # 58ä¸ªé€šé“
                sfreq=original_sfreq,
                ch_types=['eeg'] * data.shape[0]  # æ‰€æœ‰é€šé“å‡ä¸ºEEGç±»å‹
            )

            # å°†æ•°æ®è½¬æ¢ä¸ºMNE Rawå¯¹è±¡ï¼ˆç”¨äºæ»¤æ³¢å’Œé™é‡‡æ ·ï¼‰
            raw = mne.io.RawArray(data, info)


            raw.filter(
                l_freq=0.5,
                h_freq=40,
                fir_design='firwin',  # ä¸ç¦»çº¿ç›¸åŒçš„FIRè®¾è®¡
                verbose=False  # å…³é—­å†—ä½™è¾“å‡º
            )
            raw.resample(target_sfreq, verbose=False)
            data_processed = raw.get_data()
            data_reshaped = np.expand_dims(data_processed, axis=0)  # æ·»åŠ æ ·æœ¬ç»´åº¦ â†’ (1, 58, 1000)
            data_reshaped = np.expand_dims(data_reshaped, axis=1)  # æ·»åŠ é€šé“ç»´åº¦ â†’ (1, 1, 58, 1000)
            # print(f"å®æ—¶æ•°æ®è°ƒæ•´åå½¢çŠ¶: {data_reshaped.shape}")  # ç¡®è®¤å½¢çŠ¶æ­£ç¡®
            p_labels = model_predict(data_reshaped, srate=self.srate, model=self.estimator, device=self.device)
            predicted_label = int(p_labels[0])
            print(f"ğŸ”® å®æ—¶é¢„æµ‹æ ‡ç­¾: {predicted_label} (0=å·¦æ‰‹, 1=å³æ‰‹)")

            # æ§åˆ¶æœºæ¢°æ‰‹ï¼ˆç”¨çº¿ç¨‹é¿å…é˜»å¡ï¼‰
            threading.Thread(
                target=self.control_robot,
                args=(predicted_label,),
                daemon=True
            ).start()

            # LSLå‘é€ç»“æœ
            lsl_label = [predicted_label + 1]  # æ ‡ç­¾ä»1å¼€å§‹
            max_attempts = 50
            for attempt in range(max_attempts):
                if self.outlet.have_consumers():
                    try:
                        self.outlet.push_sample(lsl_label)
                        print(f"âœ… LSLå‘é€æˆåŠŸ (ç¬¬{attempt + 1}æ¬¡)")
                        break
                    except Exception as send_error:
                        print(f"âŒ LSLå‘é€å¤±è´¥: {send_error}")
                time.sleep(0.01)

        except Exception as e:
            print(f"âš ï¸ å®æ—¶å¤„ç†é”™è¯¯: {e}")

    def post(self):
        """æ¸…ç†èµ„æº"""
        # å…³é—­ä¸²å£
        if self.serial_left and self.serial_left.is_open:
            self.serial_left.close()
            print(f"ğŸ”Œ å·²å…³é—­å·¦æ‰‹æœºæ¢°æ‰‹è¿æ¥")
        if self.serial_right and self.serial_right.is_open:
            self.serial_right.close()
            print(f"ğŸ”Œ å·²å…³é—­å³æ‰‹æœºæ¢°æ‰‹è¿æ¥")
        print("ğŸ§¹ FeedbackWorker å·²å…³é—­")



if __name__ == '__main__':
    # æ”¾å¤§å™¨çš„é‡‡æ ·ç‡
    srate = 1000
    stim_interval = [0, 4]
    stim_labels = list(range(1, 3))
    print(stim_labels)
    cnts = 4  # æ•°æ®æ–‡ä»¶æ•°ç›®

    lsl_source_id = 'meta_online_worker'
    feedback_worker_name = 'feedback_worker'
    # print('1')
    worker = FeedbackWorker(
        stim_interval=stim_interval,
        stim_labels=stim_labels,
        srate=srate,
        lsl_source_id=lsl_source_id,
        timeout=5e-2,
        worker_name=feedback_worker_name
    )

    marker = Marker(interval=stim_interval, srate=srate,
                    events=stim_labels)        # æ‰“æ ‡ç­¾å…¨ä¸º1

    ns = Neuracle(
        device_address=('127.0.0.1', 8712),
        srate=srate,
        num_chans=65)  # NeuroScan parameter
    # ä¸nså»ºç«‹tcpè¿æ¥
    # print(ns.device_address)
    ns.connect_tcp()

    # nså¼€å§‹é‡‡é›†æ³¢å½¢æ•°æ®
    # ns.start_acq()

    # # register workeræ¥å®ç°åœ¨çº¿å¤„ç†
    ns.register_worker(feedback_worker_name, worker, marker)
    print("å·²æ³¨å†Œçš„workerï¼š", ns._workers.keys())  # ä¿®æ”¹ä¸º _workers

    # å¼€å¯åœ¨çº¿å¤„ç†è¿›ç¨‹
    ns.up_worker(feedback_worker_name)
    print(f"worker è¿›ç¨‹çŠ¶æ€: {'å­˜æ´»' if worker.is_alive() else 'å·²ç»ˆæ­¢'}")  # æ–°å¢

    import threading
    import numpy as np

    time.sleep(1)

    # nså¼€å§‹æˆªå–æ•°æ®çº¿ç¨‹ï¼Œå¹¶æŠŠæ•°æ®ä¼ é€’æ•°æ®ç»™å¤„ç†è¿›ç¨‹
    ns.start_trans()

    # ä»»æ„é”®å…³é—­å¤„ç†è¿›ç¨‹
    input('press any key to close\n')
    # å…³é—­å¤„ç†è¿›ç¨‹
    ns.down_worker('feedback_worker')

    # ç­‰å¾… 1s
    time.sleep(1)


    # nsåœæ­¢åœ¨çº¿æˆªå–çº¿ç¨‹
    ns.stop_trans()

    # nsåœæ­¢é‡‡é›†æ³¢å½¢æ•°æ®
    ns.stop_acq()

    ns.close_connection()  # ä¸nsæ–­å¼€è¿æ¥

    ns.clear()

    # #
